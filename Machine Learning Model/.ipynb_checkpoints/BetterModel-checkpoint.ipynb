{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "c24ae64c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 338 files belonging to 25 classes.\n",
      "Found 71 files belonging to 25 classes.\n"
     ]
    }
   ],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "\n",
    "train_dir = \"Class25_Dataset/train/\"\n",
    "test_dir = \"Class25_Dataset/test/\"\n",
    "\n",
    "\n",
    "\n",
    "train_data = tf.keras.preprocessing.image_dataset_from_directory(train_dir,\n",
    "                                                                                label_mode=\"categorical\",\n",
    "                                                                                image_size=IMG_SIZE)\n",
    "                                                                                \n",
    "test_data = tf.keras.preprocessing.image_dataset_from_directory(test_dir,\n",
    "                                                                label_mode=\"categorical\",\n",
    "                                                                image_size=IMG_SIZE,\n",
    "                                                                shuffle=False)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e6329a0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<BatchDataset element_spec=(TensorSpec(shape=(None, 224, 224, 3), dtype=tf.float32, name=None), TensorSpec(shape=(None, 25), dtype=tf.float32, name=None))>\n"
     ]
    }
   ],
   "source": [
    "print(train_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "7de012c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "checkpoint_path = \"better_model_checkpoint\"\n",
    "checkpoint_callback = tf.keras.callbacks.ModelCheckpoint(checkpoint_path,\n",
    "                                                         save_weights_only=True, # save only the model weights\n",
    "                                                         monitor=\"val_accuracy\", # save the model weights which score the best validation accuracy\n",
    "                                                         save_best_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "0530ef49",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers.experimental import preprocessing\n",
    "from tensorflow.keras.models import Sequential\n",
    "\n",
    "# original_data = Sequential([\n",
    "#   preprocessing.RandomRotation(0), \n",
    "# ], name=\"original_data\")\n",
    "\n",
    "data_augmentation = Sequential([\n",
    "  preprocessing.RandomRotation(0),\n",
    "  preprocessing.RandomFlip(\"horizontal\"),\n",
    "  preprocessing.RandomRotation(0.2), \n",
    "  preprocessing.RandomHeight(0.2),\n",
    "  preprocessing.RandomWidth(0.2),\n",
    "  preprocessing.RandomZoom(0.2),\n",
    "  preprocessing.RandomContrast(0.2)\n",
    "], name=\"data_augmentation\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d0e31cb3",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model = tf.keras.applications.EfficientNetB0(include_top=False)\n",
    "base_model.trainable = False\n",
    "\n",
    "\n",
    "inputs = layers.Input(shape=(224, 224, 3), name=\"input_layer\")\n",
    "\n",
    "x = data_augmentation(inputs)\n",
    "x = base_model(x, training=False) \n",
    "x = layers.GlobalAveragePooling2D(name=\"global_average_pooling\")(x) \n",
    "outputs = layers.Dense(len(train_data.class_names), activation=\"softmax\", name=\"output_layer\")(x) \n",
    "model = tf.keras.Model(inputs, outputs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "3a4fe52c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_layer (InputLayer)    [(None, 224, 224, 3)]     0         \n",
      "                                                                 \n",
      " data_augmentation (Sequenti  (None, 224, 224, 3)      0         \n",
      " al)                                                             \n",
      "                                                                 \n",
      " efficientnetb0 (Functional)  (None, None, None, 1280)  4049571  \n",
      "                                                                 \n",
      " global_average_pooling (Glo  (None, 1280)             0         \n",
      " balAveragePooling2D)                                            \n",
      "                                                                 \n",
      " output_layer (Dense)        (None, 25)                32025     \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 4,081,596\n",
      "Trainable params: 32,025\n",
      "Non-trainable params: 4,049,571\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "070a5171",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/21\n",
      "11/11 [==============================] - 18s 1s/step - loss: 3.2156 - accuracy: 0.0799 - val_loss: 3.0042 - val_accuracy: 0.0986\n",
      "Epoch 2/21\n",
      "11/11 [==============================] - 12s 1s/step - loss: 2.7149 - accuracy: 0.3491 - val_loss: 2.6987 - val_accuracy: 0.2535\n",
      "Epoch 3/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 2.3535 - accuracy: 0.4704 - val_loss: 2.4494 - val_accuracy: 0.3239\n",
      "Epoch 4/21\n",
      "11/11 [==============================] - 14s 1s/step - loss: 2.0646 - accuracy: 0.6154 - val_loss: 2.2533 - val_accuracy: 0.3803\n",
      "Epoch 5/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.7827 - accuracy: 0.7071 - val_loss: 2.1044 - val_accuracy: 0.3944\n",
      "Epoch 6/21\n",
      "11/11 [==============================] - 15s 1s/step - loss: 1.6180 - accuracy: 0.7574 - val_loss: 1.9931 - val_accuracy: 0.4085\n",
      "Epoch 7/21\n",
      "11/11 [==============================] - 14s 1s/step - loss: 1.5004 - accuracy: 0.7692 - val_loss: 1.9002 - val_accuracy: 0.4225\n",
      "Epoch 8/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.3580 - accuracy: 0.7811 - val_loss: 1.8241 - val_accuracy: 0.4789\n",
      "Epoch 9/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.2373 - accuracy: 0.8343 - val_loss: 1.7506 - val_accuracy: 0.4789\n",
      "Epoch 10/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 1.1282 - accuracy: 0.8254 - val_loss: 1.7024 - val_accuracy: 0.5070\n",
      "Epoch 11/21\n",
      "11/11 [==============================] - 14s 1s/step - loss: 1.1074 - accuracy: 0.8254 - val_loss: 1.6619 - val_accuracy: 0.5352\n",
      "Epoch 12/21\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.9851 - accuracy: 0.8609 - val_loss: 1.6105 - val_accuracy: 0.5493\n",
      "Epoch 13/21\n",
      " 9/11 [=======================>......] - ETA: 2s - loss: 0.9373 - accuracy: 0.8750"
     ]
    }
   ],
   "source": [
    "model.compile(loss=\"categorical_crossentropy\",\n",
    "              optimizer=tf.keras.optimizers.Adam(),\n",
    "              metrics=[\"accuracy\"])\n",
    "\n",
    "# Fit\n",
    "history_base_model = model.fit(train_data,\n",
    "                                           epochs=21, \n",
    "                                           validation_data=test_data,\n",
    "                                           validation_steps=len(test_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "e6ef8871",
   "metadata": {},
   "outputs": [],
   "source": [
    "base_model.trainable = True\n",
    "\n",
    "# Refreeze every layer except for the last 5\n",
    "for layer in base_model.layers[:-5]:\n",
    "  layer.trainable = False\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "3cb1a237",
   "metadata": {},
   "outputs": [],
   "source": [
    "new_model = model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "924bf90b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer=tf.keras.optimizers.Adam(1e-4), # 10x lower learning rate than default\n",
    "              metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "4a3bb344",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 21/31\n",
      "11/11 [==============================] - 21s 1s/step - loss: 0.7014 - accuracy: 0.8994 - val_loss: 1.3286 - val_accuracy: 0.5775\n",
      "Epoch 22/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.6405 - accuracy: 0.8817 - val_loss: 1.2914 - val_accuracy: 0.5634\n",
      "Epoch 23/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.5796 - accuracy: 0.8935 - val_loss: 1.2513 - val_accuracy: 0.6056\n",
      "Epoch 24/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.4645 - accuracy: 0.9231 - val_loss: 1.1760 - val_accuracy: 0.6338\n",
      "Epoch 25/31\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.4429 - accuracy: 0.9053 - val_loss: 1.1624 - val_accuracy: 0.6338\n",
      "Epoch 26/31\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3850 - accuracy: 0.9112 - val_loss: 1.1602 - val_accuracy: 0.6056\n",
      "Epoch 27/31\n",
      "11/11 [==============================] - 12s 1s/step - loss: 0.3678 - accuracy: 0.9201 - val_loss: 1.1321 - val_accuracy: 0.6479\n",
      "Epoch 28/31\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3733 - accuracy: 0.9201 - val_loss: 1.1013 - val_accuracy: 0.6479\n",
      "Epoch 29/31\n",
      "11/11 [==============================] - 14s 1s/step - loss: 0.3195 - accuracy: 0.9438 - val_loss: 1.0816 - val_accuracy: 0.6479\n",
      "Epoch 30/31\n",
      "11/11 [==============================] - 68s 6s/step - loss: 0.2916 - accuracy: 0.9408 - val_loss: 1.1075 - val_accuracy: 0.6197\n",
      "Epoch 31/31\n",
      "11/11 [==============================] - 13s 1s/step - loss: 0.2719 - accuracy: 0.9349 - val_loss: 1.0984 - val_accuracy: 0.6338\n"
     ]
    }
   ],
   "source": [
    "fine_tune_epochs = 31\n",
    "\n",
    "history_model_fine_tune = model.fit(train_data,\n",
    "                                                     epochs=fine_tune_epochs,\n",
    "                                                     validation_data=test_data,\n",
    "                                                     validation_steps=len(test_data),\n",
    "                                                     initial_epoch=history_base_model.epoch[-1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "1dcd3d50",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "18\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "-1"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "IMAGE_SHAPE = (224, 224)\n",
    "IMAGE_SHAPE+(3,)\n",
    "test_dir = \"C:\\\\Users\\\\bhave\\\\Project-1\\\\Class25_Dataset\\\\train\\\\a\\\\2.jpeg\"\n",
    "img = cv2.imread(test_dir)\n",
    "img_resize = cv2.resize(img , IMAGE_SHAPE)\n",
    "predicted = model.predict(np.array([img_resize]))\n",
    "ind = np.argmax(predicted , axis = 1)\n",
    "index = ind[0]\n",
    "print(index)\n",
    "cv2.imshow('detected', img)\n",
    "cv2.waitKey(0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "a095a387",
   "metadata": {},
   "outputs": [],
   "source": [
    "model_json = model.to_json()\n",
    "with open(\"better_model.json\" , \"w\") as json_file:\n",
    "    json_file.write(model_json)\n",
    "model.save_weights(\"better_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "d56ef96a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import model_from_json\n",
    "import json\n",
    "\n",
    "model_file = open(\"better_model.json\", \"r\")\n",
    "model_json = model_file.read()\n",
    "model = model_from_json(model_json)\n",
    "model.load_weights(\"better_model_weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c1fbc034",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
